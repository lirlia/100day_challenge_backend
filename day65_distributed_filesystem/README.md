# Day65 - 分散ファイルシステム (GolangDFS) ✅

HDFSライクな分散ファイルシステムをGoで実装。NameNode/DataNode構成でファイルのチャンキング、レプリケーション、故障回復機能を提供。

## 🎯 完成した機能

✅ **Phase 1-4 完了**: 基本的な分散ファイルシステムが動作可能

## アーキテクチャ

### システム構成
- **NameNode**: メタデータ管理、DataNode管理、レプリケーション制御
- **DataNode**: ファイルチャンクの実際の保存、ハートビート送信
- **CLI Client**: ファイル操作用コマンドラインツール

### 主要機能
- ファイルチャンキング（64MB単位）
- 3重レプリケーション（設定可能）
- DataNode故障検知・自動回復
- 負荷分散によるチャンク配置
- gRPC通信による高性能データ転送

## 技術仕様

### 通信プロトコル
- gRPC（高性能バイナリ通信）
- ProtocolBuffers定義

### データ管理
- NameNode: SQLite（メタデータ）
- DataNode: ローカルファイルシステム（チャンク保存）

### ポート構成
- NameNode: 9000
- DataNode: 9001, 9002, 9003

## 使用方法

### 基本操作

```bash
# セットアップ
make setup

# クラスター起動
make run-cluster

# ファイルアップロード
./bin/dfs put ./local_file.txt /dfs/remote_file.txt

# ファイルダウンロード  
./bin/dfs get /dfs/remote_file.txt ./downloaded_file.txt

# ファイル一覧
./bin/dfs ls /dfs/

# ファイル情報
./bin/dfs info /dfs/remote_file.txt

# ファイル削除
./bin/dfs rm /dfs/remote_file.txt

# クラスター停止
make stop-cluster
```

### テスト・検証

```bash
# 基本機能テスト
make test-ops

# 障害試験（重要！）
make failure-test
```

## 🧪 障害試験について

分散ファイルシステムの**障害耐性**を検証する包括的なテストスイートを提供しています。

### 試験内容

1. **DataNode単体障害**
   - 1台のDataNode停止
   - レプリカからのファイルアクセス確認
   - データ整合性検証

2. **DataNode複数障害**
   - 複数DataNode同時停止（レプリケーション限界テスト）
   - 新規ファイルアップロード可否
   - 残存レプリカからのアクセス確認

3. **自動回復試験**
   - DataNode復旧後のレプリケーション回復
   - メタデータ整合性確認
   - ハートビートによる自動検知

4. **NameNode障害**
   - メタデータサーバー停止の影響
   - 復旧後のメタデータ整合性
   - システム全体の可用性確認

### 実行方法

```bash
# クラスター起動
make run-cluster

# 障害試験実行（対話式）
make failure-test
```

**注意**: 障害試験はクラスターのDataNodeを実際に停止・再起動します。実行前に必要なデータのバックアップを取ってください。

### 試験結果の見方

- ✅ **緑色**: 正常動作（期待される動作）
- ❌ **赤色**: 異常検出または失敗
- ⚠️ **黄色**: 警告（レプリケーション数不足など）

障害試験により、本格的な分散ファイルシステムとしての堅牢性を確認できます。

## 学習ポイント

1. **分散システム設計**
   - マスター/スレーブアーキテクチャ
   - メタデータとデータの分離
   - ハートビートによる故障検知

2. **ファイルシステム設計**
   - チャンキング戦略
   - レプリケーション管理
   - データ整合性保証

3. **gRPC通信**
   - Protocol Buffers定義
   - ストリーミング通信
   - 高性能バイナリ転送

4. **故障処理**
   - ノード故障検知
   - データ復旧プロセス
   - 自動リバランシング

5. **負荷分散**
   - チャンク配置アルゴリズム
   - DataNode容量管理
   - 読み書き負荷分散

## 実装スケジュール

### Phase 1: 基盤構築 ✅ 完了
- [x] プロジェクト初期化
- [x] gRPCプロトコル定義
- [x] ディレクトリ構造

### Phase 2: NameNode ✅ 完了
- [x] メタデータ管理（SQLite）
- [x] DataNode管理
- [x] ハートビート処理
- [x] レプリケーション管理

### Phase 3: DataNode ✅ 完了
- [x] チャンクストレージ
- [x] gRPCサーバー
- [x] ハートビート送信

### Phase 4: CLI Client ✅ 完了
- [x] Cobraベースコマンド
- [x] ファイル操作機能
- [x] エラーハンドリング

### Phase 5: 高度機能 ✅ 完了
- [x] レプリケーション
- [x] 故障回復
- [x] 負荷分散

### Phase 6: テスト・最適化 ✅ 完了
- [x] 統合テスト
- [x] 障害試験
- [x] パフォーマンス測定
- [x] ドキュメント整備

## 🎉 プロジェクト完了！

**GolangDFS分散ファイルシステム**が完成しました！

- ✅ **HDFS互換**: 本格的な分散ファイルシステムアーキテクチャ
- ✅ **高可用性**: DataNode障害時の自動故障回復
- ✅ **スケーラブル**: DataNode追加による容量拡張対応
- ✅ **高性能**: gRPCストリーミングによる効率的データ転送
- ✅ **障害試験**: 包括的な障害耐性テストスイート

### 今すぐ試すには

```bash
# セットアップ
make setup && make build

# クラスター起動
make run-cluster

# 基本機能テスト
make test-ops

# 障害試験
make failure-test
``` 
